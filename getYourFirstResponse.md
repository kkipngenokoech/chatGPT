# OPENAI API KEY

the first thing is to ensure that you get your API key

visit the [openai website](https://platform.openai.com/account/api-keys)

login/sign up if you don't have an account yet

in this tutorial we are going to use python and so in your favorite editor:

1. create a python file [openai.py](./openai.py)
2. then ensure you pip install openai since we are going to use that module - `pip install openai`
3. then we are going to load the api key and relevant python libraries

```python
import openai
openai.api_key = "Paste your API key here"
```

with that we have already loaded our api key to our python file, and we can start using the openai functionalities

## passing a prompt to openai

we are going to pass a message to openai model, and to do that we are going to use a python function, so right below where you pasted your API key:

```py

prompt = "Give me a list of the 7 wonders of the world"
def getResponse(prompt, model = "gpt-3.5-turbo",temperature=0, max_tokens=500):
    response = openai.ChatCompletion.create(
        model = model,
        messages = prompt,
        temperature = temperature,
        max_tokens = max_tokens
    )
    return response.choices[0].message['content']
```

so with the function above, you will have passed a message to openai model and gotten a response.

## dissecting the method getResponse

as you can see, our  python method `getResponse` takes 4 parameters:

1. prompt
2. model
3. temperature
4. max_tokens

### prompt

this is the message we want to pass to openai so that we get a response for, it can be a question, a statement or any sentence really.

### model

what is a model? we are going to keep it short and simple here. In a normal conversation, you normally talk with other people and they give you some information or response. in this situation, you are having a conversation between you and a machine (model)

in a normal conversation, you can choose to converse with a lecturer or a student, or your workmate or even your soulmate, so the parameter model we are passing here tells openai that i want to have a conversation with this particular model.

openai have released several versions of its language model each with different strengths and weaknesses, they include:

1. GPT
2. GPT-2
3. GPT-3
    - and a lot more

Each of these models represented significant advancements in terms of size, performance, and capabilities

more information about these models can be found at [openai documentation](https://platform.openai.com/docs/models)

for our case for example, we are going to use `gpt-3.5-turbo` you can see it's strengths [here](https://platform.openai.com/docs/models/gpt-3-5)

### temperature

this represents the degree of randomness of the model's output

if you keep it at 0, the model will output the same output over and over again, the more random your model will be, the more it will generate different results when given the same input

to increase the model's randomness you can increase the temperature

### max_tokens

this is the maximum number of tokens that the model can output.Tokens are chunks of text that can be as short as one character or as long as one word, depending on the language.

By setting the max_tokens parameter to a specific value, you can control the length of the response generated by the model.

For example, if you set max_tokens to 50, the model will generate a response that contains a maximum of 50 tokens.

## printing the response

so to print the response you just have to call the method and store the results in a variable then print the variable:

```python
response = getResponse()
print(response)
```

with that you have completed CHATGPT 101

